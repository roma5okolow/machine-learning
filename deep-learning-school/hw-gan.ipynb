{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<p style=\"align: center;\"><img align=center src=\"https://drive.google.com/uc?export=view&id=1I8kDikouqpH4hf7JBiSYAeNT2IO52T-T\" width=600 height=480/></p>\n<h3 style=\"text-align: center;\"><b>Школа глубокого обучения ФПМИ МФТИ</b></h3>\n\n<h3 style=\"text-align: center;\"><b>Домашнее задание. Generative adversarial networks</b></h3>\n\n","metadata":{"id":"xG34LB_ov1SV"}},{"cell_type":"markdown","source":"В этом домашнем задании вы обучите GAN генерировать лица людей и посмотрите на то, как можно оценивать качество генерации","metadata":{"id":"JEZSpS6zv5BP"}},{"cell_type":"code","source":"import os\nfrom torch.utils.data import DataLoader\nfrom torchvision.datasets import ImageFolder\nimport torchvision.transforms as tt\nimport torch\nimport torch.nn as nn\nimport cv2\nfrom tqdm.notebook import tqdm\nfrom torchvision.utils import save_image\nfrom torchvision.utils import make_grid\nimport numpy as np\nimport matplotlib.pyplot as plt\n#import seaborn as sns\nfrom tqdm.notebook import tqdm\nfrom IPython.display import clear_output\n%matplotlib inline\n\n#sns.set(style='darkgrid', font_scale=1.2)","metadata":{"id":"iIXHhd1ZvuSY","execution":{"iopub.status.busy":"2022-06-02T15:09:58.863553Z","iopub.execute_input":"2022-06-02T15:09:58.864526Z","iopub.status.idle":"2022-06-02T15:10:01.484973Z","shell.execute_reply.started":"2022-06-02T15:09:58.864386Z","shell.execute_reply":"2022-06-02T15:10:01.484067Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"## Часть 1. Подготовка данных (1 балл)","metadata":{"id":"WrmSpt5e478V"}},{"cell_type":"markdown","source":"В качестве обучающей выборки возьмем часть датасета [Flickr Faces](https://github.com/NVlabs/ffhq-dataset), который содержит изображения лиц людей в высоком разрешении (1024х1024). Оригинальный датасет очень большой, поэтому мы возьмем его часть. Скачать датасет можно [здесь](https://drive.google.com/file/d/1KWPc4Pa7u2TWekUvNu9rTSO0U2eOlZA9/view?usp=sharing)","metadata":{"id":"Dp2fR2Jd2eoh"}},{"cell_type":"code","source":"#from google.colab import drive\n#drive.mount('/content/drive', force_remount=True)","metadata":{"id":"dVDwXV-2uiPx","outputId":"1e2f12ee-d865-418c-d31e-3b365ba82ef0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#cd /content/drive/MyDrive/Colab Notebooks/ML/DLS","metadata":{"id":"E6OD1Hf3x1xj","outputId":"c44cc86f-ae5f-4180-9c4f-7e5208875af8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#!ls","metadata":{"id":"YxqV-CL7F7FJ","outputId":"2ba9d25a-cd94-43c7-ca4f-b831587f2613"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"DATA_DIR = '../input/facesdatasetsmall'","metadata":{"id":"zY44P8lwuww3","execution":{"iopub.status.busy":"2022-06-02T15:10:20.203546Z","iopub.execute_input":"2022-06-02T15:10:20.204377Z","iopub.status.idle":"2022-06-02T15:10:20.208646Z","shell.execute_reply.started":"2022-06-02T15:10:20.204341Z","shell.execute_reply":"2022-06-02T15:10:20.207770Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"Давайте загрузим наши изображения. Напишите функцию, которая строит DataLoader для изображений, при этом меняя их размер до нужного значения (размер 1024 слишком большой, поэтому мы рекомендуем взять размер 128 либо немного больше)","metadata":{"id":"s0uiO3Za40iK"}},{"cell_type":"code","source":"def get_dataloader(image_size, batch_size):\n  \"\"\"\n  Builds dataloader for training data.\n  Use tt.Compose and tt.Resize for transformations\n  :param image_size: height and wdith of the image\n  :param batch_size: batch_size of the dataloader\n  :returns: DataLoader object \n  \"\"\"\n  # TODO: resize images, convert them to tensors and build dataloader\n  data_ds = ImageFolder(DATA_DIR, transform = tt.Compose([\n      tt.Resize(image_size),\n      tt.ToTensor()\n  ]))\n\n  loader = DataLoader(data_ds, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)\n  return loader","metadata":{"id":"CObqZZVdyyVg","execution":{"iopub.status.busy":"2022-06-02T15:10:21.747172Z","iopub.execute_input":"2022-06-02T15:10:21.747956Z","iopub.status.idle":"2022-06-02T15:10:21.761974Z","shell.execute_reply.started":"2022-06-02T15:10:21.747912Z","shell.execute_reply":"2022-06-02T15:10:21.759598Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"image_size = 128\nbatch_size = 64\n\n#TODO: build dataloader and transfer it to device\ntrain_dl = get_dataloader(image_size, batch_size)","metadata":{"id":"iwoDGf7myHPI","execution":{"iopub.status.busy":"2022-06-02T15:10:28.752999Z","iopub.execute_input":"2022-06-02T15:10:28.753911Z","iopub.status.idle":"2022-06-02T15:10:33.360900Z","shell.execute_reply.started":"2022-06-02T15:10:28.753870Z","shell.execute_reply":"2022-06-02T15:10:33.360107Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"batch = next(iter(train_dl))[0]\nprint(batch.size())","metadata":{"id":"jlVDyP8hynKD","outputId":"b7537a66-e4c6-4836-f927-5bc4f8f897ee","execution":{"iopub.status.busy":"2022-06-02T15:10:37.609978Z","iopub.execute_input":"2022-06-02T15:10:37.610338Z","iopub.status.idle":"2022-06-02T15:10:51.421964Z","shell.execute_reply.started":"2022-06-02T15:10:37.610309Z","shell.execute_reply":"2022-06-02T15:10:51.420900Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"len(train_dl.dataset)","metadata":{"execution":{"iopub.status.busy":"2022-06-02T15:11:41.055110Z","iopub.execute_input":"2022-06-02T15:11:41.055483Z","iopub.status.idle":"2022-06-02T15:11:41.061583Z","shell.execute_reply.started":"2022-06-02T15:11:41.055453Z","shell.execute_reply":"2022-06-02T15:11:41.060595Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# посмотрим на наши изображения\nn_pic = 10\n\nplt.figure(figsize=(18, 8))\nfor i in range(n_pic):\n    plt.subplot(2, n_pic // 2, i + 1)\n    plt.imshow(batch[i].permute(1, 2, 0))\n    plt.axis('off')\nplt.suptitle(\"Some examples from dataset\")\nplt.show()","metadata":{"id":"_-OE_ZTwyMGP","outputId":"d7672b31-8c18-4758-a6c5-0527b3c0f921","execution":{"iopub.status.busy":"2022-06-01T18:23:00.651644Z","iopub.execute_input":"2022-06-01T18:23:00.652057Z","iopub.status.idle":"2022-06-01T18:23:01.411858Z","shell.execute_reply.started":"2022-06-01T18:23:00.652025Z","shell.execute_reply":"2022-06-01T18:23:01.410879Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"## Часть 2. Построение и обучение модели (2 балла)","metadata":{"id":"TgJiWnue5Aim"}},{"cell_type":"markdown","source":"Сконструируйте генератор и дискриминатор. Помните, что:\n* дискриминатор принимает на вход изображение (тензор размера `3 x image_size x image_size`) и выдает вероятность того, что изображение настоящее (тензор размера 1)\n\n* генератор принимает на вход тензор шумов размера `latent_size x 1 x 1` и генерирует изображение размера `3 x image_size x image_size`","metadata":{"id":"n00W_EXg72er"}},{"cell_type":"code","source":"discriminator = nn.Sequential(\n    # in: 3 x 128 x 128\n    nn.Conv2d(3, 64, kernel_size=4, stride=2, padding=1, bias=False),\n    nn.BatchNorm2d(64),\n    nn.MaxPool2d(kernel_size=2),\n    nn.LeakyReLU(0.2, inplace=True),\n    # out: 64 x 32 x 32\n\n    nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1, bias=False),\n    nn.BatchNorm2d(128),\n    nn.MaxPool2d(kernel_size=2),\n    nn.LeakyReLU(0.2, inplace=True),\n    # out: 128 x 8 x 8\n\n    nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1, bias=False),\n    nn.BatchNorm2d(256),\n    nn.MaxPool2d(kernel_size=2),\n    nn.LeakyReLU(0.2, inplace=True),\n    # out: 256 x 2 x 2\n    \n    nn.Conv2d(256, 1, kernel_size=2, stride=1, padding=0, bias=False),\n    # out: 1 x 1 x 1\n\n    nn.Flatten(),\n    nn.Sigmoid()\n    )   ","metadata":{"id":"zLMOs5O51BdB","execution":{"iopub.status.busy":"2022-06-02T17:38:19.562116Z","iopub.execute_input":"2022-06-02T17:38:19.562491Z","iopub.status.idle":"2022-06-02T17:38:19.579758Z","shell.execute_reply.started":"2022-06-02T17:38:19.562462Z","shell.execute_reply":"2022-06-02T17:38:19.578991Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"latent_size = 64\n\ngenerator = nn.Sequential(\n    # in: latent_size x 1 x 1\n\n    nn.ConvTranspose2d(latent_size, 1024, kernel_size=4, stride=1, padding=0, bias=False),\n    nn.BatchNorm2d(1024),\n    nn.ReLU(True),\n    # out: 1024 x 4 x 4\n\n    nn.ConvTranspose2d(1024, 512, kernel_size=4, stride=2, padding=1, bias=False),\n    nn.BatchNorm2d(512),\n    nn.ReLU(True),\n    # out: 512 x 8 x 8\n\n    nn.ConvTranspose2d(512, 256, kernel_size=4, stride=2, padding=1, bias=False),\n    nn.BatchNorm2d(256),\n    nn.ReLU(True),\n    # out: 256 x 16 x 16\n\n    nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1, bias=False),\n    nn.BatchNorm2d(128),\n    nn.ReLU(True),\n    # out: 128 x 32 x 32\n\n    nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1, bias=False),\n    nn.BatchNorm2d(64),\n    nn.ReLU(True),\n    # out: 64 x 64 x 64\n\n    nn.ConvTranspose2d(64, 3, kernel_size=4, stride=2, padding=1, bias=False),\n    nn.Sigmoid()\n    # out: 3 x 128 x 128\n)","metadata":{"id":"Qrnjt3qZ1IBj","execution":{"iopub.status.busy":"2022-06-02T17:38:21.406620Z","iopub.execute_input":"2022-06-02T17:38:21.407038Z","iopub.status.idle":"2022-06-02T17:38:21.596825Z","shell.execute_reply.started":"2022-06-02T17:38:21.407002Z","shell.execute_reply":"2022-06-02T17:38:21.595824Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"markdown","source":"Перейдем теперь к обучению нашего GANа. Алгоритм обучения следующий:\n1. Учим дискриминатор:\n  * берем реальные изображения и присваиваем им метку 1\n  * генерируем изображения генератором и присваиваем им метку 0\n  * обучаем классификатор на два класса\n\n2. Учим генератор:\n  * генерируем изображения генератором и присваиваем им метку 0\n  * предсказываем дискриминаторором, реальное это изображение или нет\n\n\nВ качестве функции потерь берем бинарную кросс-энтропию","metadata":{"id":"MDHQaIzQ0B4S"}},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\ndevice","metadata":{"id":"ORiAUwn77bdc","outputId":"a441208b-8ea6-4aef-84b3-327ffcf1f0c3","execution":{"iopub.status.busy":"2022-06-02T17:38:23.905184Z","iopub.execute_input":"2022-06-02T17:38:23.905570Z","iopub.status.idle":"2022-06-02T17:38:23.911589Z","shell.execute_reply.started":"2022-06-02T17:38:23.905533Z","shell.execute_reply":"2022-06-02T17:38:23.910842Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"def fit(model, criterion, n_epochs, lr, dataloader, buffer_size):\n    # buffer size is a number of batches that can be included in buffer\n    # TODO: build optimizers and train your GAN\n    gen_losses = []\n    disc_losses = []\n    real_scores = []\n    fake_scores = []\n\n    model[\"discriminator\"].train()\n    model[\"generator\"].train()\n    torch.cuda.empty_cache()\n    \n    buffer_flag = 0\n    buffer = []\n\n    optimizer = {\n        \"discriminator\": torch.optim.Adam(model[\"discriminator\"].parameters(), lr=lr),\n        \"generator\": torch.optim.Adam(model[\"generator\"].parameters(), lr=lr)\n    }\n\n    for epoch in tqdm(range(n_epochs)):\n        gen_losses_per_epoch = []\n        disc_losses_per_epoch = []\n        real_scores_per_epoch = []\n        fake_scores_per_epoch = []\n        \n        if epoch == 0:\n            buffer_flag = 1\n        \n        for real_images, _ in tqdm(dataloader):\n            \n            real_images = real_images.to(device)\n            shape = real_images.size()\n            \n            # Train discriminator\n            optimizer[\"discriminator\"].zero_grad()\n\n            # Pass real images through discriminator\n            real_preds = model[\"discriminator\"](real_images)\n            #noise = torch.FloatTensor(shape[0], 1).uniform_(0, 0.05).to(device)\n            real_labels = torch.ones(shape[0], 1, device=device)\n            real_loss = criterion[\"discriminator\"](real_preds, real_labels)\n            cur_real_score = torch.mean(real_preds).item()\n\n            # Create buffer\n            if buffer_flag == 1:\n                for i in range(buffer_size):\n                    latent = torch.randn(shape[0], latent_size, 1, 1, device=device)\n                    fake_images = model[\"generator\"](latent)\n                    buffer.append(fake_images)\n                buffer_flag = 0\n                \n            # Generate images\n            latent = torch.randn(shape[0], latent_size, 1, 1, device=device)\n            fake_images_cur1 = buffer.pop(0)\n            fake_images1 = model[\"generator\"](latent)\n            buffer.append(fake_images1)\n            \n            # Pass fake images through discriminator\n            fake_labels = torch.zeros(shape[0], 1, device=device)\n            fake_preds = model[\"discriminator\"](fake_images_cur1)\n            fake_loss = criterion[\"discriminator\"](fake_preds, fake_labels)\n            cur_fake_score = torch.mean(fake_preds).item()\n            \n            real_scores_per_epoch.append(cur_real_score)\n            fake_scores_per_epoch.append(cur_fake_score)\n            \n            # Update discriminator loss\n            disc_loss = real_loss + fake_loss\n            disc_loss.backward()\n            optimizer[\"discriminator\"].step()\n            disc_losses_per_epoch.append(disc_loss.item())\n        \n            # Train generator\n            optimizer[\"generator\"].zero_grad()\n\n            # Generate fake images\n            latent = torch.randn(shape[0], latent_size, 1, 1, device=device)\n            fake_images_cur2 = buffer[0]\n            fake_images2 = model[\"generator\"](latent)\n            buffer.append(fake_images2)\n\n            # Try to fool discriminator\n            preds = model[\"discriminator\"](fake_images_cur2)\n            labels = torch.ones(shape[0], 1, device=device)\n            gen_loss = criterion[\"generator\"](preds, labels)\n\n            # Update generators weights\n            gen_loss.backward()\n            optimizer[\"generator\"].step()\n            gen_losses_per_epoch.append(gen_loss.item())\n\n        #Record losses and scores\n        gen_losses.append(np.mean(gen_losses_per_epoch))\n        disc_losses.append(np.mean(disc_losses_per_epoch))\n        real_scores.append(np.mean(real_scores_per_epoch))\n        fake_scores.append(np.mean(fake_scores_per_epoch))\n\n        # show intermediate results\n        clear_output(wait=True)\n        fig = plt.figure(figsize=(24, 8))\n        for i in range(6):\n            ax = fig.add_subplot(2, 6, i + 1)\n            ax.imshow(fake_images[i].permute(1, 2, 0).detach().cpu().numpy())\n            ax.set_title(\"Fake image\")\n            ax.axis('off')\n\n        #draw losses and scores\n        if(epoch != 0):\n            ax1 = fig.add_subplot(2, 2, 3)\n            epochs = np.arange(1, epoch + 2)\n            ax1.plot(epochs, gen_losses, label='generator')\n            ax1.plot(epochs, disc_losses, label='discriminator')\n            ax1.set_title(\"BCE loss\")\n            ax1.set_xlabel('epochs')\n            ax1.set_ylabel('loss')\n            ax1.grid()\n            ax1.legend(fontsize=14)\n            \n            ax2 = fig.add_subplot(2, 2, 4)\n            epochs = np.arange(1, epoch + 2)\n            ax2.plot(epochs, real_scores, label='real')\n            ax2.plot(epochs, fake_scores, label='fake')\n            ax2.set_title(\"Scores\")\n            ax2.set_xlabel('epochs')\n            ax2.set_ylabel('score')\n            ax2.grid()\n            ax2.legend(fontsize=14)\n\n        plt.suptitle(f\"{epoch+1} / {n_epochs} - generator_loss: {gen_losses[-1]:0.4f}, discriminator: {disc_losses[-1]:0.4f}\")\n        plt.show()\n\n        #if (epoch + 1 == epochs):\n        #    torch.save(model.state_dict(), 'gan')\n\n    return gen_losses, disc_losses, real_scores, fake_scores","metadata":{"id":"Q_nMgY3w10EC","execution":{"iopub.status.busy":"2022-06-02T18:48:26.859410Z","iopub.execute_input":"2022-06-02T18:48:26.859935Z","iopub.status.idle":"2022-06-02T18:48:26.888300Z","shell.execute_reply.started":"2022-06-02T18:48:26.859877Z","shell.execute_reply":"2022-06-02T18:48:26.887150Z"},"trusted":true},"execution_count":118,"outputs":[]},{"cell_type":"code","source":"lr = 0.0003\n\nmodel = {\n    \"discriminator\": discriminator.to(device),\n    \"generator\": generator.to(device)\n}\n\ncriterion_bce = {\n    \"discriminator\": nn.BCELoss(),\n    \"generator\": nn.BCELoss()\n}\n\ncriterion_mse = {\n    \"discriminator\": nn.MSELoss(),\n    \"generator\": nn.MSELoss()\n}","metadata":{"id":"NOu_m1BBFB_U","execution":{"iopub.status.busy":"2022-06-02T18:48:28.910209Z","iopub.execute_input":"2022-06-02T18:48:28.910929Z","iopub.status.idle":"2022-06-02T18:48:28.919066Z","shell.execute_reply.started":"2022-06-02T18:48:28.910887Z","shell.execute_reply":"2022-06-02T18:48:28.918040Z"},"trusted":true},"execution_count":119,"outputs":[]},{"cell_type":"code","source":"%%time\nepochs = 30\ngen_losses, disc_losses, real_scores, fake_scores = fit(model, criterion_mse, epochs, lr, train_dl, 5)","metadata":{"id":"JUPh9bXe6760","outputId":"395ebdf2-f4b8-48ff-80df-15cca8281855","execution":{"iopub.status.busy":"2022-06-02T18:48:30.666088Z","iopub.execute_input":"2022-06-02T18:48:30.666448Z","iopub.status.idle":"2022-06-02T18:48:40.194135Z","shell.execute_reply.started":"2022-06-02T18:48:30.666416Z","shell.execute_reply":"2022-06-02T18:48:40.193157Z"},"trusted":true},"execution_count":120,"outputs":[]},{"cell_type":"markdown","source":"Постройте графики лосса для генератора и дискриминатора. Что вы можете сказать про эти графики?","metadata":{"id":"VkecCSn69DLe"}},{"cell_type":"markdown","source":"## Часть 3. Генерация изображений (1 балл)","metadata":{"id":"kuL3ZZvX5G29"}},{"cell_type":"markdown","source":"Теперь давайте оценим качество получившихся изображений. Напишите функцию, которая выводит изображения, сгенерированные нашим генератором","metadata":{"id":"7q9_WFIl-Bf6"}},{"cell_type":"code","source":"n_images = 10\nfixed_latent = torch.randn(n_images, latent_size, 1, 1, device=device)\nfake_images = model[\"generator\"](fixed_latent)","metadata":{"id":"Z1tuaMVu1Jqx","outputId":"7a838ad2-36fa-4be3-bf73-bec0aebd8516","execution":{"iopub.status.busy":"2022-06-02T16:59:01.797989Z","iopub.execute_input":"2022-06-02T16:59:01.798341Z","iopub.status.idle":"2022-06-02T16:59:01.805747Z","shell.execute_reply.started":"2022-06-02T16:59:01.798312Z","shell.execute_reply":"2022-06-02T16:59:01.804772Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"def show_images(generated, n_images):\n  # TODO: show generated images\n    fig = plt.figure(figsize=(24, 8))\n    for i in range(n_images):\n        ax = fig.add_subplot(2, 5, i + 1)\n        ax.imshow(fake_images[i].permute(1, 2, 0).detach().cpu().numpy())\n        ax.axis('off')","metadata":{"id":"D-ZmT6qm4ai5","execution":{"iopub.status.busy":"2022-06-02T17:03:21.735007Z","iopub.execute_input":"2022-06-02T17:03:21.735361Z","iopub.status.idle":"2022-06-02T17:03:21.741654Z","shell.execute_reply.started":"2022-06-02T17:03:21.735330Z","shell.execute_reply":"2022-06-02T17:03:21.740355Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"show_images(fake_images, n_images)","metadata":{"execution":{"iopub.status.busy":"2022-06-02T17:03:22.139874Z","iopub.execute_input":"2022-06-02T17:03:22.140235Z","iopub.status.idle":"2022-06-02T17:03:23.089885Z","shell.execute_reply.started":"2022-06-02T17:03:22.140199Z","shell.execute_reply":"2022-06-02T17:03:23.088945Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"markdown","source":"Как вам качество получившихся изображений?","metadata":{"id":"BHqPK3xs-Z-7"}},{"cell_type":"markdown","source":"## Часть 4. Leave-one-out-1-NN classifier accuracy (6 баллов)","metadata":{"id":"c0z41dA05KAa"}},{"cell_type":"markdown","source":"### 4.1. Подсчет accuracy (4 балла)","metadata":{"id":"2C9V8DHX_ipy"}},{"cell_type":"markdown","source":"Не всегда бывает удобно оценивать качество сгенерированных картинок глазами. В качестве альтернативы вам предлагается реализовать следующий подход:\n  * Сгенерировать столько же фейковых изображений, сколько есть настоящих в обучающей выборке. Присвоить фейковым метку класса 0, настоящим – 1.\n  * Построить leave-one-out оценку: обучить 1NN Classifier (`sklearn.neighbors.KNeighborsClassifier(n_neighbors=1)`) предсказывать класс на всех объектах, кроме одного, проверить качество (accuracy) на оставшемся объекте. В этом вам поможет `sklearn.model_selection.LeaveOneOut`","metadata":{"id":"9wT2uUb4_rku"}},{"cell_type":"code","source":"","metadata":{"id":"vsrgX9X4BfE0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Что вы можете сказать о получившемся результате? Какой accuracy мы хотели бы получить и почему?","metadata":{"id":"jRU47nCzCVnP"}},{"cell_type":"markdown","source":"### 4.2. Визуализация распределений (2 балла)","metadata":{"id":"FqzHnPOACgoZ"}},{"cell_type":"markdown","source":"Давайте посмотрим на то, насколько похожи распределения настоящих и фейковых изображений. Для этого воспользуйтесь методом, снижающим размерность (к примеру, TSNE) и изобразите на графике разным цветом точки, соответствующие реальным и сгенерированным изображенияи","metadata":{"id":"EweiItWFDYO0"}},{"cell_type":"code","source":"","metadata":{"id":"UZBJWkWdCepj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Прокомментируйте получившийся результат:","metadata":{"id":"ZVZe9tt8DuYh"}},{"cell_type":"code","source":"","metadata":{"id":"z__a1XTPEKaa"},"execution_count":null,"outputs":[]}]}